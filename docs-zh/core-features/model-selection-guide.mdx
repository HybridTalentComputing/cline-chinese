---
title: "模型选择指南"
description: "最后更新：2025 年 8 月 20 日。"
---

新模型层出不穷，因此本指南专注于目前与 Cline 配合良好的模型。随着格局变化，我们会持续更新。

<Callout type="tip">
**模型选择新手？** 请先从 [Cline 学习路径的模块 2](https://cline.bot/learn) 开始，获取关于选择和配置模型的综合指南。
</Callout>

## 什么是 AI 模型？

将 AI 模型视为驱动 Cline 的"大脑"。当你要求 Cline 编写代码、修复错误或重构项目时，实际上是模型在理解你的请求并生成响应。

**关键点：**
- **模型是训练好的 AI 系统**，能够理解自然语言和代码
- **不同模型有不同优势**——有些擅长复杂推理，其他则优先考虑速度或成本
- **你选择 Cline 使用哪个模型**——就像为不同任务选择不同的专家
- **模型通过 API 提供商访问**——Anthropic、OpenAI 和 OpenRouter 等公司托管这些模型

**为什么重要：** 你选择的模型直接影响 Cline 的能力、响应质量、速度和成本。高级模型可能完美处理复杂重构但成本更高，而经济型模型以极低价格完成常规任务效果极佳。

## 在 Cline 中选择模型

按照这 5 个简单步骤，让 Cline 使用你喜欢的 AI 模型运行起来：

### 步骤 1：打开 Cline 设置

首先，你需要访问 Cline 的配置面板。

**打开设置的两种方式：**
- **快速方法**：点击 Cline 聊天界面右上角的 **齿轮图标 (⚙️)**
- **命令面板**：按 **Cmd/Ctrl + Shift + P** → 输入 "Cline: Open Settings"

<Frame>
  <img src="https://storage.googleapis.com/cline_public_images/step1-config.png" alt="Cline Settings Panel" />
</Frame>

设置面板将打开，显示配置选项，顶部是 "API Provider"。

<Note>
设置面板会记住你上次配置的设置，所以你只需设置一次。
</Note>

### 步骤 2：选择 API 提供商

从下拉菜单中选择你喜欢的 AI 提供商。

<Frame>
  <img src="https://storage.googleapis.com/cline_public_images/step2-provider.png" alt="Cline Settings Panel" />
</Frame>

**热门提供商概览：**

| 提供商 | 最适合 | 备注 |
|----------|----------|-------|
| **Cline** | 最简单的设置 | 无需 API 密钥，访问多个模型包括隐身模型 |
| **OpenRouter** | 追求价值 | 多个模型，价格有竞争力 |
| **Anthropic** | 可靠性 | Claude 模型，最可靠的工具使用 |
| **OpenAI** | 最新技术 | GPT 模型 |
| **Google Gemini** | 大上下文 | Google 的 AI 模型 |
| **AWS Bedrock** | 企业级 | 高级功能 |
| **Ollama** | 隐私 | 本地运行模型 |

查看[完整提供商列表](/provider-config)了解更多选项，包括 Cerebras、Vertex AI、Azure 等。

<Info>
**初学者推荐**：以 **Cline** 作为你的提供商开始——无需管理 API 密钥，即时访问多个模型，通过合作伙伴提供商偶尔提供免费推理。
</Info>

### 步骤 3：添加你的 API 密钥（或登录）

下一步取决于你选择了哪个提供商。

#### 如果你选择了 **Cline** 作为提供商：

- **不需要 API 密钥！** 只需用你的 Cline 账户登录
- 出现提示时点击 **Sign In** 按钮
- 你将被重定向到 [app.cline.bot](https://app.cline.bot) 进行身份验证
- 登录后，返回到你的 IDE

#### 如果你选择了其他任何提供商：

你需要从选择的提供商处获取 API 密钥：

1. **访问提供商网站获取 API 密钥：**
   - **Anthropic**：[console.anthropic.com](https://console.anthropic.com/)
   - **OpenRouter**：[openrouter.ai/keys](https://openrouter.ai/keys)
   - **OpenAI**：[platform.openai.com/api-keys](https://platform.openai.com/api-keys)
   - **Google**：[aistudio.google.com/apikey](https://aistudio.google.com/apikey)
   - **其他**：参见[提供商设置指南](/provider-config)

2. **在提供商网站上生成新的 API 密钥**

3. **将 API 密钥复制**到剪贴板

4. **在 Cline 设置的 "API Key" 字段中粘贴你的密钥**

5. **自动保存**——你的密钥安全存储在编辑器的密钥存储中

<Frame>
  <img src="https://storage.googleapis.com/cline_public_images/step3-API.png" alt="Cline API Selection" />
</Frame>

<Warning>
**大多数提供商需要付款**：大多数提供商在生成密钥前需要付款信息。你只需为你使用的部分付费（通常每个编码任务 $0.01-$0.10）。
</Warning>

### 步骤 4：选择你的模型

添加 API 密钥（或登录）后，**"Model"** 下拉菜单将可用。

<Frame>
  <img src="https://storage.googleapis.com/cline_public_images/step4-model.png" alt="Cline Model Selection" />
</Frame>

**快速模型选择指南：**

| 你的优先级 | 选择此模型 | 原因 |
|---------------|-------------------|-----|
| **最高可靠性** | Claude Sonnet 4.5 | 最可靠的工具使用，擅长复杂任务 |
| **最佳性价比** | DeepSeek V3 或 Qwen3 Coder | 经济价格下的出色性能 |
| **最快速度** | Cerebras 上的 Qwen3 Coder | 闪电般快速的响应 |
| **本地运行** | 任何 Ollama 模型 | 完全隐私，无需互联网 |
| **最新功能** | GPT-5 | OpenAI 的最新功能 |

不确定选哪个？从 **Claude Sonnet 4.5**（可靠性）或 **DeepSeek V3**（性价比）开始。

<Tip>
你可以随时切换模型而不会丢失对话。尝试不同模型，找到最适合你特定任务的选项。
</Tip>

查看下面的[模型比较表](#current-top-models)了解详细规格和定价。

### 步骤 5：开始使用 Cline

**恭喜！你已经完成所有设置。** 以下是如何开始使用 Cline 编码：

1. **在 Cline 聊天框中输入你的请求**
   - 示例："创建一个登录表单的 React 组件"
   - 示例："调试这个 TypeScript 错误"
   - 示例："重构这个函数以提高效率"

2. **按 Enter** 或点击发送图标提交

## 选择合适的模型

选择合适的模型需要平衡几个因素。使用此框架找到你的理想匹配：

<Note>
**专业提示**：为计划模式和执行模式配置不同的模型。充分利用每个模型的优势。例如，使用经济型模型进行规划讨论，使用高级模型进行实现。
</Note>

### 关键选择因素

| 因素 | 需要考虑的方面 | 建议 |
|--------|------------------|----------------|
| **任务复杂性** | 简单修复 vs 复杂重构 | 常规任务用经济型模型；复杂工作用高级模型 |
| **预算** | 月度消费能力 | \$10-\$30：经济型，\$30-\$100：中端，\$100+：高级 |
| **上下文窗口** | 项目大小和文件数量 | 小：32K-128K，中：128K-200K，大：400K+ |
| **速度** | 响应时间要求 | 交互式：快速模型，后台：推理模型可以 |
| **工具可靠性** | 复杂操作 | Claude 擅长工具使用；用你的工作流测试其他模型 |
| **提供商** | 访问和定价需求 | OpenRouter：许多选项，直接：更快/可靠，本地：隐私 |



## 模型比较资源

获取详细的模型比较、定价和性能指标，请参阅：
- [**模型比较与定价**](/model-config/model-comparison) - 完整的定价表和性能基准测试
- [**上下文窗口指南**](/model-config/context-windows) - 理解和优化上下文使用

## 开源 vs 闭源

### 开源优势
- **多个提供商**竞争托管它们
- **更低的价格**由于竞争
- **提供商选择**——如果一个宕机可以切换
- **更快的创新**周期

### 可用的开源模型
- **Qwen3 Coder** (Apache 2.0)
- **Z AI GLM 4.5** (MIT)
- **Kimi K2** (开源)
- **DeepSeek 系列** (各种许可证)

## 快速决策矩阵

| 如果你想要... | 使用这个 |
|----------------|----------|
| 东西就能用 | Claude Sonnet 4.5 |
| 省钱 | DeepSeek V3 或 Qwen3 变体 |
| 巨大的上下文窗口 | Gemini 2.5 Pro 或 Claude Sonnet 4.5 |
| 开源 | Qwen3 Coder、Z AI GLM 4.5 或 Kimi K2 |
| 最新技术 | GPT-5 |
| 速度 | Cerebras 上的 Qwen3 Coder（当前最快） |

## 其他人在用什么

查看 [OpenRouter 的 Cline 使用统计](https://openrouter.ai/apps?url=https%3A%2F%2Fcline.bot%2F) 了解社区的真实使用模式。
