---
title: "Cerebras"
description: "了解如何配置和使用 Cerebras 的超快速推理与 Cline。通过晶圆级芯片架构体验高达每秒 2,600 tokens 的速度和实时推理模型。"
---

Cerebras 通过其革命性的晶圆级芯片架构提供世界上最快的 AI 推理。与传统 GPU 从外部内存传输模型权重不同，Cerebras 将整个模型存储在芯片上，消除了带宽瓶颈并实现高达每秒 2,600 tokens 的速度——通常比 GPU 快 20 倍。

**网站：** [https://cloud.cerebras.ai/](https://cloud.cerebras.ai/)

### 获取 API 密钥

1.  **注册/登录：** 访问 [Cerebras Cloud](https://cloud.cerebras.ai/) 并创建账户或登录。
2.  **导航到 API 密钥：** 访问仪表板中的 API 密钥部分。
3.  **创建密钥：** 生成新的 API 密钥。为其指定描述性名称（例如"Cline"）。
4.  **复制密钥：** 立即复制 API 密钥。安全存储它。

### 支持的模型

Cline 支持以下 Cerebras 模型：

-   `zai-glm-4.6` - 智能通用模型，1,500 tokens/秒
-   `qwen-3-235b-a22b-instruct-2507` - 高级指令遵循模型
-   `qwen-3-235b-a22b-thinking-2507` - 具有逐步思维的推理模型
-   `llama-3.3-70b` - Meta 的 Llama 3.3 模型，针对速度进行了优化
-   `qwen-3-32b` - 紧凑而强大的通用任务模型

### 在 Cline 中配置

1.  **打开 Cline 设置：** 在 Cline 面板中点击设置图标（⚙️）。
2.  **选择提供商：** 从"API 提供商"下拉菜单中选择"Cerebras"。
3.  **输入 API 密钥：** 将您的 Cerebras API 密钥粘贴到"Cerebras API 密钥"字段中。
4.  **选择模型：** 从"模型"下拉菜单中选择您想要的模型。
5.  **（可选）自定义基础 URL：** 大多数用户不需要调整此设置。

### Cerebras 的晶圆级优势

Cerebras 从根本上重新构想了 AI 硬件架构以解决推理速度问题：

#### 晶圆级架构
传统 GPU 使用独立的芯片进行计算和内存，迫使它们不断来回传输模型权重。Cerebras 构建了世界上最大的 AI 芯片——一个将整个模型存储在芯片上的晶圆级引擎。没有外部内存，没有带宽瓶颈，没有等待。

#### 革命性速度
- **高达每秒 2,600 tokens** - 通常比 GPU 快 20 倍
- **单秒推理** - 过去需要几分钟的事情现在瞬间发生
- **实时应用** - 推理模型对交互使用变得实用
- **无带宽限制** - 整个模型存储在芯片上消除了内存瓶颈

#### Cerebras 扩展定律
Cerebras 发现**更快的推理实现更智能的 AI**。现代推理模型在回答之前生成数千个 tokens 作为"内心独白"。在传统硬件上，这需要太长时间而无法实时使用。Cerebras 使推理模型足够快以用于日常应用程序。

#### 无损质量
与牺牲准确性的其他速度优化不同，Cerebras 在提供前所未有的速度的同时保持完整的模型质量。您获得前沿模型的智能和轻量级模型的响应速度。

在他们的博客文章中了解更多关于 Cerebras 技术的信息：
- [Cerebras 扩展定律：更快的推理是更智能的 AI](https://www.cerebras.ai/blog/the-cerebras-scaling-law-faster-inference-is-smarter-ai)
- [介绍 Cerebras Code](https://www.cerebras.ai/blog/introducing-cerebras-code)

### Cerebras Code 计划

Cerebras 为开发人员提供专业计划：

#### Code Pro（$50/月）
- 访问 Qwen3-Coder，具有快速、高上下文补全
- 每天高达 2400 万 tokens
- 适合独立开发者和周末项目
- 每天 3-4 小时的不间断编码

#### Code Max（$200/月）
- 重大编码工作流支持
- 每天高达 1.2 亿 tokens
- 完美用于全职开发和多智能体系统
- 无每周限制，无 IDE 锁定

### 特殊功能

#### 免费层级
`qwen-3-coder-480b-free` 模型免费提供高性能推理访问——在以速度为重点的提供商中独一无二。

#### 实时推理
像 `qwen-3-235b-a22b-thinking-2507` 这样的推理模型可以在一秒钟内完成复杂的多步推理，使它们对交互式开发工作流实用化。

#### 编码专业化
Qwen3-Coder 模型专门针对编程任务进行了优化，在编码基准测试中提供与 Claude Sonnet 4 和 GPT-4.1 相当的性能。

#### 无 IDE 锁定
与任何 OpenAI 兼容工具一起使用——Cursor、Continue.dev、Cline 或任何其他支持 OpenAI 端点的编辑器。

### 提示和注意事项

-   **速度优势：** Cerebras 擅长使推理模型对实时使用实用化。非常适合需要多次 LLM 调用的智能体工作流。
-   **免费层级：** 从免费模型开始体验 Cerebras 速度，然后再升级到付费计划。
-   **上下文窗口：** 模型支持从 64K 到 128K tokens 的上下文窗口，以包含大量代码上下文。
-   **速率限制：** 为开发工作流设计的慷慨速率限制。检查您的仪表板以获取当前限制。
-   **定价：** 具有显著速度优势的竞争性定价。访问 [Cerebras Cloud](https://cloud.cerebras.ai/)获取当前费率。
-   **实时应用：** 非常适合 AI 响应时间很重要的应用程序——代码生成、调试和交互式开发。
