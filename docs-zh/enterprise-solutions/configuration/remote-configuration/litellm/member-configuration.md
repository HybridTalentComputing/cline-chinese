---
title: "在 VS Code 中配置 LiteLLM（成员）"
sidebarTitle: "配置 LiteLLM（成员）"
description: "工程师在管理员设置后通过 VS Code 连接到组织 LiteLLM 代理的指南"
---

作为团队成员，你可以将本地开发环境连接到组织的 LiteLLM 代理设置。本指南将引导你在 VS Code 中配置连接，以便你可以通过组织的统一代理界面使用多个 AI 模型。你的管理员已经配置了提供商设置——你只需要添加你的凭证即可开始。

## 开始之前

要成功连接到组织的 LiteLLM 代理，你需要准备一些事项。

**安装并配置了 Cline 扩展**  
必须在 VS Code 中安装 Cline 扩展，并且你需要登录到组织账户。如果你尚未安装 Cline，请遵循我们的[安装指南](/getting-started/installing-cline)。

<Info>
**快速检查**：在 VS Code 中打开 Cline 面板。如果你在左下角看到你的组织名称，则你已正确登录。
</Info>

**组织 LiteLLM 代理的访问凭证**  
你需要访问组织 LiteLLM 代理的凭证。这可能是 API 密钥，或者代理可能配置为在你的网络内开放访问。

<Note>
如果你不确定需要什么凭证，请与你的管理员或 IT 团队联系，了解如何访问组织的 LiteLLM 代理。
</Note>

## 配置步骤

<Steps>
<Step title="打开 Cline 设置">
打开 VS Code 并使用以下任一方法访问 Cline 设置面板：

- 在 Cline 面板中单击设置图标（⚙️）
- 单击位于聊天区域正下方的 API 提供商下拉菜单（它将显示为 `LiteLLM` 或显示特定的模型名称）

</Step>

<Step title="配置 LiteLLM 连接">
LiteLLM 配置选项取决于你的组织如何设置代理：

<AccordionGroup>
<Accordion title="API 密钥身份验证">
如果你的组织需要 API 密钥身份验证：

1. 选择或确认已选择 **LiteLLM** 提供商
2. 在 **API 密钥** 字段中输入你分配的 API 密钥
3. 基础 URL 应已由你的管理员配置
4. 单击 **保存** 以存储你的凭证

<Tip>
API 密钥本地存储在 VS Code 中，仅由 Cline 扩展使用。
</Tip>
</Accordion>

<Accordion title="开放访问（无需身份验证）">
如果你的 LiteLLM 代理配置为在你的网络内开放访问：

1. 选择或确认已选择 **LiteLLM** 提供商  
2. 将 API 密钥字段留空
3. 扩展将直接连接到配置的代理端点
4. 无需额外身份验证

<Info>
当 LiteLLM 代理部署在安全的网络环境中时，开放访问很常见。
</Info>
</Accordion>

<Accordion title="自定义配置">
如果你的组织使用自定义身份验证或特定的连接参数：

1. 遵循管理员提供的任何自定义说明
2. 如果遇到连接问题，请联系你的 IT 团队
3. 可能需要在 VS Code 之外进行额外配置

<Note>
自定义配置可能需要特定的网络设置或额外的身份验证步骤。
</Note>
</Accordion>
</AccordionGroup>
</Step>

<Step title="选择可用模型">
连接后，你将看到通过组织 LiteLLM 代理可用的模型：

- 在模型下拉列表中查看可用模型
- 模型由你管理员的代理配置决定  
- 你可以切换模型以执行不同类型的任务
- 某些模型可能会根据你的访问级别受到限制

<Tip>
**模型选择**

根据你的任务要求选择模型：
- **快速模型**（如 GPT-3.5-turbo）用于快速响应
- **强大模型**（如 GPT-4）用于复杂推理
- **专用模型**用于代码生成或特定领域
</Tip>
</Step>

<Step title="测试连接">
在 Cline 中发送测试消息以验证你的连接与 LiteLLM 代理正常工作。

<Tip>
**测试建议**

首先在计划模式下测试连接，以便在将其用于实际开发任务之前验证一切正常工作。
</Tip>
</Step>
</Steps>

## 模型使用

### 可用的模型类别
通过你的 LiteLLM 代理可用的模型通常包括：

**文本生成模型：**
- OpenAI GPT-4、GPT-3.5-turbo 变体
- Anthropic Claude 3 Sonnet、Haiku、Opus
- 开源模型如 Llama 2、Mistral

**代码专用模型：**
- OpenAI GPT-4 for code
- CodeLlama 变体
- 专用代码补全模型

**多模态模型：**
- GPT-4 Vision 用于图像分析
- 具有视觉功能的 Claude 3 模型

### 模型选择策略
根据你的开发需求选择模型：

- **快速迭代**：使用更快、更具成本效益的模型
- **复杂问题**：使用更强大的模型  
- **重度代码任务**：使用代码专用模型
- **视觉内容**：处理图像时使用多模态模型

## 故障排除

**LiteLLM 不作为提供商选项可用**  
确认你登录到了正确的 Cline 组织。验证你的管理员已保存 LiteLLM 配置，并且你具有最新版本的 Cline 扩展。

**连接错误或超时**  
验证你的网络可以访问 LiteLLM 代理端点。请与你的 IT 团队联系，了解防火墙规则或 VPN 要求。确保代理端点可从你的开发环境访问。

**身份验证失败**  
如果使用 API 密钥身份验证，验证密钥是否正确输入且未过期。联系你的管理员以确认你的密钥处于活动状态并具有适当的权限。

**模型未加载或受限**  
可用模型取决于你组织的 LiteLLM 配置。如果你需要访问特定模型或预期的模型不可用，请联系管理员。

**响应时间慢**  
响应时间取决于使用的模型和代理负载。尝试为常规任务切换到更快的模型。如果性能持续不佳，请联系管理员。

**来自特定模型的错误消息**  
某些模型可能暂时不可用或有特定限制。尝试替代模型，或者如果特定模型持续失败，请联系管理员。

## 安全最佳实践

使用组织的 LiteLLM 代理时：

- 保持你的 API 凭据安全，不要共享
- 根据你的数据敏感性使用适当的模型  
- 遵循你组织的使用指南
- 报告任何可疑活动或未授权的访问尝试
- 定期更新 Cline 扩展以获取安全补丁

你的组织管理员控制哪些模型可用以及使用策略。扩展将根据你的代理配置和访问级别自动显示可用模型。
