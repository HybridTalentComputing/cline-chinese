---
title: "OpenAI 兼容"
description: "学习如何配置 Cline 与提供 OpenAI 兼容 API 的各种 AI 模型提供商。"
---

Cline 支持广泛的 AI 模型提供商，这些提供商提供与 OpenAI API 标准兼容的 API。这允许您使用来自 OpenAI 以外的提供商的模型，同时仍然利用熟悉的 API 接口。这包括以下提供商：

-   通过 Ollama 和 LM Studio 等工具运行的**本地模型**（在各自的章节中介绍）。
-   **云提供商**，如 Perplexity、Together AI、Anyscale 等。
-   提供 OpenAI 兼容 API 端点的**任何其他提供商**。

本文档专注于设置官方 OpenAI API 以外的提供商（官方 OpenAI API 有自己的[专用配置页面](/provider-config/openai)）。

### 一般配置

在 Cline 中使用 OpenAI 兼容提供商的关键是配置这些主要设置：

1.  **基础 URL：** 这是特定于提供商的 API 端点。它不会是 `https://api.openai.com/v1`（该 URL 用于官方 OpenAI API）。
2.  **API 密钥：** 这是您从所选提供商获得的密钥。
3.  **模型 ID：** 这是您希望使用的模型的特定名称或标识符。

您将在 Cline 设置面板中找到这些设置（点击 ⚙️ 图标）：

-   **API 提供商：** 选择"OpenAI 兼容"。
-   **基础 URL：** 输入您所选提供商提供的基础 URL。**这是关键步骤。**
-   **API 密钥：** 输入来自提供商的 API 密钥。
-   **模型：** 选择或输入模型 ID。
-   **模型配置：** 此部分允许您自定义模型的高级参数，例如：
    -   最大输出令牌
    -   上下文窗口大小
    -   图像支持功能
    -   计算机使用（例如，对于具有工具/函数调用的模型）
    -   输入价格（每令牌/百万令牌）
    -   输出价格（每令牌/百万令牌）

### 支持的模型（适用于 OpenAI 原生端点）

虽然"OpenAI 兼容"提供商类型允许连接到各种端点，但如果您直接连接到官方 OpenAI API（或完全镜像它的端点），Cline 会根据其源代码中的 `openAiNativeModels` 定义识别以下模型 ID：

-   `o3-mini`
-   `o3-mini-high`
-   `o3-mini-low`
-   `o1`
-   `o1-preview`
-   `o1-mini`
-   `gpt-4o`
-   `gpt-4o-mini`

**注意：** 如果您使用不同的 OpenAI 兼容提供商（如 Together AI、Anyscale 等），可用的模型 ID 将不同。始终参考您特定提供商的文档以了解他们支持的模型名称和任何独特的配置细节。

### Cline 中的 v0（Vercel SDK）：

-   对于使用 v0 的开发者，他们的 [AI SDK 文档](https://vercel.com/docs/v0/cline) 为集成各种模型提供了有价值的见解和示例，其中许多都是 OpenAI 兼容的。这可以是理解如何在使用 Cline 与部署在 Vercel 上或与 Vercel 集成的服务时构建调用和管理配置的有用资源。

-   v0 可以在 Cline 中与 OpenAI 兼容提供商一起使用。

-   ### 快速开始

-   1. 选择 OpenAI 兼容提供商后，将基础 URL 设置为 https://api.v0.dev/v1。
-   2. 粘贴您的 v0 API 密钥
-   3. 设置模型 ID：v0-1.0-md
-   4. 点击验证以确认连接。

### 故障排除

-   **"无效的 API 密钥"：** 仔细检查您是否正确输入了 API 密钥，以及它是否适用于正确的提供商。
-   **"模型未找到"：** 确保您使用的是所选提供商的有效模型 ID，并且它在指定的基础 URL 上可用。
-   **连接错误：** 验证基础 URL 是否正确，您的提供商 API 是否可以从您的机器访问，以及没有防火墙或网络问题。
-   **意外结果：** 如果您获得意外输出，请尝试不同的模型或仔细检查所有配置参数。

通过使用 OpenAI 兼容提供商，您可以利用 Cline 的灵活性与更广泛的 AI 模型。请记住始终查阅您提供商的文档以获取最准确和最新的信息。
